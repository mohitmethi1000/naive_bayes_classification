{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yKzMWTPIdgNw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "impoting the data -> preproccession the data"
      ],
      "metadata": {
        "id": "Ebz5OmPCeJgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/datasets/email spam/combined_data.csv\")\n",
        "x = data['text']\n",
        "y = data['label']"
      ],
      "metadata": {
        "id": "TBJFgNLkdl3E"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 -> means spam\n",
        "\n",
        "0 -> means ham"
      ],
      "metadata": {
        "id": "6MG6hFUlUrLj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "splitting the data"
      ],
      "metadata": {
        "id": "K9kV7BHkUnVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_array = np.array(x)\n",
        "y_array = np.array(y)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_array, y_array, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "V7DFL58Jdpqd"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "converting the data in [0,0,0,1,0,0,0,1] - form"
      ],
      "metadata": {
        "id": "rCnRTU4mUq7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv = CountVectorizer(stop_words = 'english')\n",
        "x_train = cv.fit_transform(x_train)\n",
        "x_test = cv.transform(x_test)         # sparse matrix"
      ],
      "metadata": {
        "id": "bS02Zzzpdps0"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c50XLKuFJx2h",
        "outputId": "d7847cd8-928a-4b42-f8a4-c3a61b0c9c22"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(66758, 276601)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# implimenting multinomial naive bayes from sratch"
      ],
      "metadata": {
        "id": "7-7w9w5bdzr3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultinomialNB:\n",
        "    def __init__(self):\n",
        "        # initialize all model parameters\n",
        "        self.classes = None\n",
        "        self.class_count = {}\n",
        "        self.word_count = {}\n",
        "        self.feature_log_prob = {}\n",
        "        self.class_log_prior = {}\n",
        "        self.V = 0  # vocabulary size for laplace smoothing\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.classes = np.unique(y)\n",
        "        self.class_count = {}\n",
        "        self.word_count = {}\n",
        "        self.feature_log_prob = {}\n",
        "        self.class_log_prior = {}\n",
        "        self.V = X.shape[1]\n",
        "\n",
        "        for c in self.classes:\n",
        "            X_c = X[y == c]\n",
        "            self.class_count[c] = X_c.shape[0]\n",
        "            self.word_count[c] = X_c.sum(axis=0)\n",
        "            total_count = self.word_count[c].sum()\n",
        "            # laplace smoothing\n",
        "            self.feature_log_prob[c] = np.log((self.word_count[c] + 1) / (total_count + self.V))\n",
        "            self.class_log_prior[c] = np.log(self.class_count[c] / len(y))\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "        for i in range(X.shape[0]):\n",
        "            row = X[i]\n",
        "            log_probs = {}\n",
        "            for c in self.classes:\n",
        "                log_prob = self.class_log_prior[c]\n",
        "                log_prob += row @ self.feature_log_prob[c].T\n",
        "                log_probs[c] = log_prob\n",
        "            predicted_class = max(log_probs, key=log_probs.get)\n",
        "            predictions.append(predicted_class)\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def score(self, X, y):\n",
        "        y_pred = self.predict(X)\n",
        "        return np.mean(y_pred == y)\n",
        "\n",
        "    def top_words(self, n = 5):\n",
        "        # top words are with maximum p(x/y) for each class\n",
        "        top_words_indices = {}\n",
        "        # first geting top words\n",
        "        for c in self.classes:\n",
        "            top_words_indices[c] = np.argsort(self.feature_log_prob[c].A1)[-n:][::-1]\n",
        "\n",
        "        # now getting top words for a particular class\n",
        "        feature_names = cv.get_feature_names_out()\n",
        "        top_words = {}\n",
        "        for c in self.classes:\n",
        "            top_words[c] = feature_names[top_words_indices[c]]\n",
        "        return top_words\n"
      ],
      "metadata": {
        "id": "Ledk1eK0dpoI"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "training the model"
      ],
      "metadata": {
        "id": "44emwtMNU1ch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultinomialNB()\n",
        "model.fit(x_train, y_train)\n",
        "print('accuracy:', model.score(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AK0w2kprdply",
        "outputId": "3ef07b10-e59f-46e5-b74b-5d7976279171"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.9778310365488316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mail = \"your test is scheduled for tommorow\"\n",
        "vectorized = cv.transform([mail])\n",
        "pred = model.predict(vectorized)\n",
        "if pred == 1:\n",
        "  print(\"spam\")\n",
        "else:\n",
        "  print(\"ham\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O834Zj-0dpjE",
        "outputId": "8244a708-4c81-4e23-e5ac-647f008ad7e8"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ham\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_words = model.top_words(n = 10)"
      ],
      "metadata": {
        "id": "PtaioibISJuv"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for c, words in top_words.items():\n",
        "    print(f\"Top words for class {c}: {', '.join(words)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wf64Rw6Lg_40",
        "outputId": "af5dab34-5b0a-4aac-f21e-921bbba5118e"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top words for class 0: escapenumber, http, enron, org, com, escapelong, ect, help, samba, list\n",
            "Top words for class 1: escapenumber, escapelong, com, http, pills, escapenumbermg, price, company, save, item\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "roLI99x6hEpG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}